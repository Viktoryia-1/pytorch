{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e93248cf",
   "metadata": {
    "executionInfo": {
     "elapsed": 3091,
     "status": "ok",
     "timestamp": 1658565327808,
     "user": {
      "displayName": "Виктория Сазанчук",
      "userId": "11819426744119668182"
     },
     "user_tz": -180
    },
    "id": "e93248cf"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from Grocery_3 import Grocery_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64ccdbcf",
   "metadata": {
    "executionInfo": {
     "elapsed": 26218,
     "status": "ok",
     "timestamp": 1658565389847,
     "user": {
      "displayName": "Виктория Сазанчук",
      "userId": "11819426744119668182"
     },
     "user_tz": -180
    },
    "id": "64ccdbcf"
   },
   "outputs": [],
   "source": [
    "# здесь данные только за 2017 год. Ноутбук с предобработкой я случайно удалила(\n",
    "# здесть тренировочные данные + праздники в бинарном виде за исключением переносов\n",
    "# + стоимость топлива + характеристики товара\n",
    "# в общем, пребобработала по минимому - датасет гигантский и все работает очень медленно\n",
    "# весь 2017 мои скудные ресурсы тоже не осилили, пришлось откусить 2 месяца и предсказывать\n",
    "# только последние 2 недели\n",
    "train = pd.read_csv('final_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b5e317c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['date'] = pd.to_datetime(train['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f50a9aae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 421,
     "status": "ok",
     "timestamp": 1658565394050,
     "user": {
      "displayName": "Виктория Сазанчук",
      "userId": "11819426744119668182"
     },
     "user_tz": -180
    },
    "id": "f50a9aae",
    "outputId": "0a0af90f-84c3-440f-aa03-ef1f24183404"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>is_event</th>\n",
       "      <th>family</th>\n",
       "      <th>class</th>\n",
       "      <th>perishable</th>\n",
       "      <th>dcoilwtico</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>99197</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>53.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>103665</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>184</td>\n",
       "      <td>1</td>\n",
       "      <td>53.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>105574</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>53.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>105857</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>53.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>106716</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>53.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  store_nbr  item_nbr  unit_sales  onpromotion  is_event  family  \\\n",
       "0 2017-01-01         25     99197         1.0            0         1      12   \n",
       "1 2017-01-01         25    103665         7.0            0         1       5   \n",
       "2 2017-01-01         25    105574         1.0            0         1      12   \n",
       "3 2017-01-01         25    105857         4.0            0         1      12   \n",
       "4 2017-01-01         25    106716         2.0            0         1      12   \n",
       "\n",
       "   class  perishable  dcoilwtico  \n",
       "0     43           0       53.19  \n",
       "1    184           1       53.19  \n",
       "2     30           0       53.19  \n",
       "3     62           0       53.19  \n",
       "4     19           0       53.19  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43785670",
   "metadata": {
    "executionInfo": {
     "elapsed": 328,
     "status": "ok",
     "timestamp": 1658565417925,
     "user": {
      "displayName": "Виктория Сазанчук",
      "userId": "11819426744119668182"
     },
     "user_tz": -180
    },
    "id": "43785670"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_features, hidden_dim, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.num_features = num_features\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(input_size=self.num_features,\n",
    "                      hidden_size=self.hidden_dim,\n",
    "                      batch_first=True,\n",
    "                      num_layers=self.num_layers)\n",
    "        self.lin = nn.Linear(in_features=self.hidden_dim, \n",
    "                            out_features=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #h0 = torch.zeros(self.num_layers,\n",
    "                         #x.shape[0],\n",
    "                         #self.hidden_dim).requires_grad_()\n",
    "        #c0 = torch.zeros(self.num_layers, x.shape[0], self.hidden_dim).requires_grad_()\n",
    "        out, ht= self.rnn(x)\n",
    "        out = self.lin(out[:, -1])\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b405c2a3",
   "metadata": {
    "executionInfo": {
     "elapsed": 375,
     "status": "ok",
     "timestamp": 1658565468565,
     "user": {
      "displayName": "Виктория Сазанчук",
      "userId": "11819426744119668182"
     },
     "user_tz": -180
    },
    "id": "b405c2a3"
   },
   "outputs": [],
   "source": [
    "def train_model(data_loader, model, loss_function, optimizer, epochs_num, batch_len):\n",
    "    for epoch in tqdm(range(epochs_num)):\n",
    "        \n",
    "        num_batches = len(data_loader)\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        model.double()\n",
    "        for ind, (X, y) in enumerate(data_loader):\n",
    "            output = model(X.double())\n",
    "            loss = loss_function(output, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            if ind % batch_len == 0:\n",
    "                current_loss, current_len = loss.item() ,ind * len(X)\n",
    "                print(f'Batch_loss: {current_loss}, num_butches {ind} / {num_batches} ')\n",
    "\n",
    "        avg_loss = total_loss / num_batches     \n",
    "        print(f\"Epoch: {epoch + 1} Train loss: {avg_loss}\")\n",
    "        \n",
    "        \n",
    "#         model.eval()\n",
    "#         loss_accumed = 0\n",
    "#         for X, y in train_loader:\n",
    "#             output = model(X.double())\n",
    "#             loss = loss_function(output, y)\n",
    "#             loss_accumed += loss.item()\n",
    "#         eval_loss = loss_accumed / num_batches\n",
    "#         print(f\"Epoch: {epoch + 1} Test_loss: {eval_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i2zQCSwrI5Nc",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1658565516104,
     "user": {
      "displayName": "Виктория Сазанчук",
      "userId": "11819426744119668182"
     },
     "user_tz": -180
    },
    "id": "i2zQCSwrI5Nc"
   },
   "outputs": [],
   "source": [
    "class Grocery_3():\n",
    "    \n",
    "    def __init__(self, dataset, target, scalar):\n",
    "        self.dataset= dataset\n",
    "        self.target = target\n",
    "        self.scalar = scalar()\n",
    "        self.y = torch.tensor(self.dataset[self.target].to_numpy(dtype='float64')).unsqueeze(1)     \n",
    "        self.X = self.scalar.fit_transform(torch.tensor(self.dataset.drop(self.target, axis=1).to_numpy(dtype='float64')))\n",
    "       \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, i): \n",
    "        return self.X[i], self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e70f065",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_train = train.loc[train['date'] > '2017-05-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d822061e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8019163"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cut_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c789fcd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2017-08-15 00:00:00')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.date.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9a6f03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_len = len(train.loc[train['date'] > '2017-07-31'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "628fc9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "border = len(cut_train) - test_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "IdHExxd_JPZE",
   "metadata": {
    "executionInfo": {
     "elapsed": 4619,
     "status": "ok",
     "timestamp": 1658565523279,
     "user": {
      "displayName": "Виктория Сазанчук",
      "userId": "11819426744119668182"
     },
     "user_tz": -180
    },
    "id": "IdHExxd_JPZE"
   },
   "outputs": [],
   "source": [
    "f_train_3 = Grocery_3(cut_train[:border],'unit_sales', StandardScaler)\n",
    "f_test_3 = Grocery_3(cut_train[border:],'unit_sales', StandardScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4Vx93WpXJlDu",
   "metadata": {
    "executionInfo": {
     "elapsed": 385,
     "status": "ok",
     "timestamp": 1658565541026,
     "user": {
      "displayName": "Виктория Сазанчук",
      "userId": "11819426744119668182"
     },
     "user_tz": -180
    },
    "id": "4Vx93WpXJlDu"
   },
   "outputs": [],
   "source": [
    "train_loader_3 = torch.utils.data.DataLoader(f_train_3,\n",
    "                          batch_size=1000,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2,\n",
    "                          drop_last=True)\n",
    "test_loader_3 = torch.utils.data.DataLoader(f_test_3,\n",
    "                          batch_size=1000,\n",
    "                          shuffle=False,\n",
    "                          num_workers=1, \n",
    "                          drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "KV0iylCIJp4z",
   "metadata": {
    "executionInfo": {
     "elapsed": 377,
     "status": "ok",
     "timestamp": 1658565570049,
     "user": {
      "displayName": "Виктория Сазанчук",
      "userId": "11819426744119668182"
     },
     "user_tz": -180
    },
    "id": "KV0iylCIJp4z"
   },
   "outputs": [],
   "source": [
    "# если не поставить размер скрытого слоя равным размеру батча, вылетаю с ошибкой\n",
    "# несовпадения размерности. Так должно быть или я что-то упустила?\n",
    "model_3 = RNN(9, 1000)\n",
    "loss_3 = nn.MSELoss()\n",
    "optimizer_3 = torch.optim.Adam(model_3.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ZGQ_T_PJ0Rt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4ZGQ_T_PJ0Rt",
    "outputId": "2da3c6eb-0361-406e-fee6-fdf059414b5a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]/Users/Viktoryia/Documents/gb/env/lib/python3.9/site-packages/torch/nn/modules/loss.py:529: UserWarning: Using a target size (torch.Size([1000, 1])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch_loss: 243.08438164875133, num_butches 0 / 6448 \n",
      "Batch_loss: 1469.086419240755, num_butches 1000 / 6448 \n",
      "Batch_loss: 207.0904727225291, num_butches 2000 / 6448 \n",
      "Batch_loss: 139.9344296355253, num_butches 3000 / 6448 \n",
      "Batch_loss: 2848.459923717265, num_butches 4000 / 6448 \n",
      "Batch_loss: 188.6566576544406, num_butches 5000 / 6448 \n",
      "Batch_loss: 366.4992351166771, num_butches 6000 / 6448 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                   | 0/1 [7:41:14<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train loss: 638.5473600399507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/lw/sfx9kxt17jj8cb5s59ll44q80000gp/T/ipykernel_61964/1964970079.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/lw/sfx9kxt17jj8cb5s59ll44q80000gp/T/ipykernel_61964/3038222738.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(data_loader, model, loss_function, optimizer, epochs_num, batch_len)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mloss_accumed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# Здесь я забыла функцию доделать и передать тестовые данные,\n",
    "# повезло, что модель обучилась - нашла нужный код в документации и прогнала тест\n",
    "# очень странно на 1000 и 4000 батчах ошибка отличается. Почему так происходит?\n",
    "train_model(train_loader_3, model_3, loss_3, optimizer_3, 1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb0c9879",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_3,'favorita-grocery-sales-forecasting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7625ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('favorita-grocery-sales-forecasting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5831321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): RNN(9, 1000, batch_first=True)\n",
      "  (lin): Linear(in_features=1000, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1bfbc170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(data_loader, model, loss_function):\n",
    "\n",
    "    num_batches = len(data_loader)\n",
    "    total_loss = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_loader:\n",
    "            output = model(X)\n",
    "            total_loss += loss_function(output, y).item()\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"Test loss: {avg_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e152299f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 489.7351021578345\n"
     ]
    }
   ],
   "source": [
    "# Ошибка гигантская. Но даже эти дважды усеченные данные обрабатывались 7 часов\n",
    "test_model(test_loader_3, model, loss_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa375e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# справедливости ради - я пыталасть запустить весь 2017 в колабе\n",
    "# но после 11 часов обработки колаб отвалился, оставив на память \n",
    "# вот этот вывод (модель та-же). Ошибка ниже и вроде так не скачет,\n",
    "# но проверить на тесте увы не могу(\n",
    "\n",
    "\n",
    "#   0%|          | 0/1 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([1000, 1])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
    "#   return F.mse_loss(input, target, reduction=self.reduction)\n",
    "# Batch_loss: 199.00224025591166, num_butches 0 / 20000 \n",
    "# Batch_loss: 210.78321136725057, num_butches 1000 / 20000 \n",
    "# Batch_loss: 198.7241058906085, num_butches 2000 / 20000 \n",
    "# Batch_loss: 145.0831561674167, num_butches 3000 / 20000 \n",
    "# Batch_loss: 183.056478043171, num_butches 4000 / 20000 \n",
    "# Batch_loss: 267.8405132705958, num_butches 5000 / 20000 \n",
    "# Batch_loss: 255.53774859960197, num_butches 6000 / 20000 \n",
    "# Batch_loss: 221.25796303932802, num_butches 7000 / 20000 "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW_5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
